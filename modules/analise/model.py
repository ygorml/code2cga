"""
M√≥dulo de an√°lise de c√≥digo-fonte para gera√ß√£o de grafos de chamada.

Este m√≥dulo cont√©m a classe AnaliseModel respons√°vel por analisar arquivos
de c√≥digo-fonte usando LLMs (Modelos de Linguagem Grande) para extrair
informa√ß√µes estruturadas sobre o fluxo de execu√ß√£o e depend√™ncias.

O m√≥dulo suporta an√°lise de m√∫ltiplos arquivos com sistema completo de:
- Checkpoint inteligente para evitar an√°lises redundantes
- Pausa autom√°tica por limites de API com retentativa programada
- Timing preciso que exclui per√≠odos de pausa
- Controle de progresso com callbacks
- Extra√ß√£o robusta de JSON das respostas do LLM
- Gera√ß√£o de grafos de chamada em formato JSON
- Tratamento de erros e recupera√ß√£o

Sistema de Checkpoint:
- Verifica√ß√£o pr√©-an√°lise para evitar requisi√ß√µes redundantes
- Valida√ß√£o de configura√ß√£o para compatibilidade
- Reaproveitamento inteligente de an√°lises anteriores

Sistema de Pausa Autom√°tica:
- Detec√ß√£o autom√°tica de erros de limite de API (429, 403)
- Pausa autom√°tica com retentativa a cada 30 minutos
- Recupera√ß√£o transparente do ponto onde parou

Sistema de Timing Preciso:
- Medi√ß√£o de tempo efetivo vs tempo total
- Exclus√£o autom√°tica de per√≠odos de pausa
- Relat√≥rios detalhados de performance
"""

import os
import json
import logging
import time
import re
import threading
from typing import List, Dict, Any, Callable, Optional
from concurrent.futures import ThreadPoolExecutor, Future
import queue
import requests
from services.ollama_service import OllamaService

logger = logging.getLogger(__name__)

class AnaliseModel:
    """
    Modelo respons√°vel pela an√°lise de c√≥digo-fonte usando LLMs com sistemas avan√ßados.

    Esta classe coordena o processo de an√°lise de m√∫ltiplos arquivos de c√≥digo,
    utilizando servi√ßos de LLM (como Ollama) para extrair informa√ß√µes estruturadas
    sobre o fluxo de execu√ß√£o, depend√™ncias e arquitetura do c√≥digo.

    Principais funcionalidades:
    - Sistema de checkpoint inteligente para evitar an√°lises redundantes
    - Pausa autom√°tica por limites de API com retentativa programada
    - Timing preciso que mede tempo efetivo excluindo pausas
    - An√°lise s√≠ncrona de m√∫ltiplos arquivos
    - Controle de progresso com callbacks
    - Extra√ß√£o robusta de JSON das respostas do LLM
    - Gera√ß√£o de grafos de chamada em formato JSON
    - Tratamento de erros e recupera√ß√£o

    Attributes:
        notifier (Optional[Callable]): Servi√ßo de notifica√ß√£o para eventos
        config (Dict[str, Any]): Configura√ß√µes da an√°lise
        ollama_service (OllamaService): Servi√ßo para intera√ß√£o com Ollama
        is_running (bool): Indica se h√° uma an√°lise em execu√ß√£o
        is_paused (bool): Indica se a an√°lise est√° pausada
        is_stopped (bool): Indica se a an√°lise foi parada
        current_progress (float): Progresso atual da an√°lise (0-100)
        current_file (str): Arquivo sendo analisado atualmente
        resultados (List[Dict]): Resultados das an√°lises realizadas
        api_pause_active (bool): Indica se pausa autom√°tica por API est√° ativa
        api_pause_reason (str): Motivo da pausa autom√°tica
        api_pause_start_time (float): Timestamp de in√≠cio da pausa
        api_retry_interval (int): Intervalo de retentativa em segundos (30 min)
        api_max_retries (int): M√°ximo de tentativas de retentativa
        api_retry_count (int): Contador de tentativas realizadas
    """
    def __init__(self, notifier=None):
        """
        Inicializa uma nova inst√¢ncia do AnaliseModel com sistemas avan√ßados.

        Configura o modelo com suporte completo para checkpoint inteligente,
        pausa autom√°tica por API, e timing preciso. Inicializa o servi√ßo do
        Ollama e cria os diret√≥rios necess√°rios para armazenamento.

        Args:
            notifier (Optional[Callable]): Servi√ßo de notifica√ß√£o para eventos da an√°lise

        Note:
            Cria os diret√≥rios necess√°rios para armazenamento dos resultados,
            inicializa o servi√ßo do Ollama para intera√ß√£o com LLMs, e configura
            o sistema de pausa autom√°tica com intervalo de 30 minutos e m√°ximo
            de 10 tentativas de retentativa.
        """
        self.notifier = notifier
        self.config = self._get_default_config()
        self.ollama_service = OllamaService(base_url=self.config.get('llm_url', 'http://localhost:11434'))
        self.garantir_pastas()

        # Sistema simplificado - sem threads complexas
        self.is_running = False
        self.is_paused = False
        self.is_stopped = False
        self.current_progress = 0
        self.current_file = ""
        self.resultados = []

        # Sistema de pausa autom√°tica por limite de API
        self.api_pause_active = False
        self.api_pause_reason = None
        self.api_pause_start_time = None
        self.api_retry_thread = None
        self.api_retry_interval = 30 * 60  # 30 minutos em segundos
        self.api_max_retries = 10  # M√°ximo de tentativas
        self.api_retry_count = 0

        # Sistema de debug para valida√ß√£o JSON
        self._last_validation_error = None

        logger.info("AnaliseModel instanciado (vers√£o simplificada).")

    def _ativar_pausa_api(self, motivo: str):
        """
        Ativa o sistema de pausa autom√°tica por limite de API.

        Este m√©todo √© chamado automaticamente quando s√£o detectados erros
        de limite de API (429, 403, quota exceeded). Ele interrompe a an√°lise
        atual e inicia um thread em background para retentativas autom√°ticas
        a cada 30 minutos, com m√°ximo de 10 tentativas.

        Args:
            motivo (str): Descri√ß√£o do motivo da pausa (ex: "rate_limit", "quota_exceeded")

        Note:
            - Define api_pause_active=True para sinalizar estado de pausa
            - Registra timestamp de in√≠cio para c√°lculos de timing
            - Inicia thread de retentativa autom√°tica se n√£o estiver ativo
            - Notifica usu√°rio sobre pausa e pr√≥ximo tempo de tentativa

        Raises:
            None: M√©todo trata exce√ß√µes internamente
        """
        if self.api_pause_active:
            return  # J√° est√° pausado

        self.api_pause_active = True
        self.api_pause_reason = motivo
        self.api_pause_start_time = time.time()
        self.is_paused = True  # Pausa a an√°lise principal

        logger.warning(f"üö¶ Pausa autom√°tica ativada: {motivo}")
        if self.notifier:
            self.notifier.warning(f"‚è∏Ô∏è An√°lise pausada: {motivo}. Retentativa em 30 minutos...")

        # Inicia thread de retentativa
        self._iniciar_retentativa_api()

    def _iniciar_retentativa_api(self):
        """
        Inicia thread para retentativas autom√°ticas da API
        """
        if self.api_retry_thread and self.api_retry_thread.is_alive():
            return  # J√° existe uma thread de retentativa

        def retry_worker():
            while self.api_pause_active and self.api_retry_count < self.api_max_retries:
                time.sleep(self.api_retry_interval)  # Espera 30 minutos
                self.api_retry_count += 1

                logger.info(f"üîÑ Tentativa {self.api_retry_count}/{self.api_max_retries} de reconex√£o com API...")
                if self.notifier:
                    self.notifier.info(f"üîÑ Tentativa {self.api_retry_count}/{self.api_max_retries} de reconex√£o...")

                # Testa a conex√£o com a API
                if self.ollama_service.check_connection():
                    logger.info("‚úÖ API respondeu! Retomando an√°lise...")
                    if self.notifier:
                        self.notifier.success("‚úÖ API dispon√≠vel! Retomando an√°lise...")

                    self._desativar_pausa_api()
                    break
                else:
                    logger.warning(f"‚ùå API ainda indispon√≠vel. Pr√≥xima tentativa em 30 minutos...")
                    if self.notifier:
                        self.notifier.warning(f"‚ùå API ainda indispon√≠vel. Tentativa {self.api_retry_count + 1}/{self.api_max_retries} em 30 min...")

            # Se esgotou as tentativas
            if self.api_retry_count >= self.api_max_retries:
                logger.error("üö´ N√∫mero m√°ximo de retentativas esgotado. An√°lise interrompida.")
                if self.notifier:
                    self.notifier.error("üö´ M√°ximo de retentativas esgotado. Verifique manualmente a API.")
                self.parar_analise()

        self.api_retry_thread = threading.Thread(target=retry_worker, daemon=True)
        self.api_retry_thread.start()

    def _desativar_pausa_api(self):
        """
        Desativa o sistema de pausa autom√°tica e retoma a an√°lise.

        Este m√©todo √© chamado quando a API volta a responder ou quando o
        usu√°rio for√ßa uma retentativa. Ele reseta o estado de pausa e
        retoma a an√°lise do ponto onde parou.

        Note:
            - Define api_pause_active=False para desativar estado de pausa
            - Calcula e registra tempo total de pausa para precis√£o de timing
            - Reseta contador de tentativas de retentativa
            - Retoma an√°lise principal definindo is_paused=False
            - Notifica usu√°rio sobre retomada bem-sucedida

        Raises:
            None: M√©todo trata exce√ß√µes internamente
        """
        if not self.api_pause_active:
            return

        self.api_pause_active = False
        self.api_pause_reason = None
        self.api_pause_start_time = None
        self.is_paused = False  # Retoma a an√°lise principal
        self.api_retry_count = 0

        logger.info("üü¢ Pausa autom√°tica desativada. An√°lise retomada.")

    def obter_status_pausa_api(self) -> Dict[str, Any]:
        """
        Retorna informa√ß√µes sobre o status da pausa por API
        """
        if not self.api_pause_active:
            return {
                'ativa': False,
                'motivo': None,
                'tempo_esperado': 0,
                'tentativas': self.api_retry_count
            }

        tempo_esperado = time.time() - self.api_pause_start_time
        proxima_tentativa = self.api_retry_interval - (tempo_esperado % self.api_retry_interval)

        return {
            'ativa': True,
            'motivo': self.api_pause_reason,
            'tempo_esperado_segundos': int(tempo_esperado),
            'proxima_tentativa_segundos': int(proxima_tentativa),
            'tentativas': self.api_retry_count,
            'maximo_tentativas': self.api_max_retries
        }

    def _get_default_config(self) -> Dict[str, Any]:
        """
        Retorna a configura√ß√£o padr√£o para an√°lise de c√≥digo.

        Returns:
            Dict[str, Any]: Dicion√°rio com configura√ß√µes padr√£o incluindo:
                - nivel_analise: N√≠vel de detalhamento da an√°lise
                - incluir_comentarios: Se deve analisar coment√°rios
                - analisar_dependencias: Se deve analisar depend√™ncias
                - llm_url: URL do servidor LLM
                - llm_modelo: Modelo LLM a ser usado
                - llm_tamanho_contexto: Tamanho m√°ximo do contexto
                - llm_temperatura: Temperatura de gera√ß√£o do LLM
        """
        return {
            'nivel_analise': 'detalhado',
            'incluir_comentarios': True,
            'analisar_dependencias': True,
            'gerar_json': True,
            'gerar_explicabilidade': True,
            'limite_linhas': 1000,
            'linguagem': 'c',
            'threads': 1,
            'pasta_inspecao': 'inspecao/',
            # Configura√ß√µes do LLM
            'llm_url': 'http://localhost:11434',
            'llm_modelo': 'llama2',
            'llm_tamanho_contexto': 4096,
            'llm_temperatura': 0.7
        }

    def _get_extensoes_por_linguagem(self) -> Dict[str, List[str]]:
        """
        Retorna um dicion√°rio com as extens√µes de arquivo permitidas por linguagem.

        Returns:
            Dict[str, List[str]]: Mapeamento de linguagem para lista de extens√µes
        """
        return {
            'c': ['.c', '.h', '.cpp', '.hpp', '.cc', '.cxx', '.c++'],
            'python': ['.py', '.pyx', '.pyi'],
            'java': ['.java', '.class', '.jar'],
            'javascript': ['.js', '.jsx', '.mjs', '.cjs'],
            'typescript': ['.ts', '.tsx'],
            'go': ['.go'],
            'rust': ['.rs', '.toml'],
            'php': ['.php', '.phtml', '.php3', '.php4', '.php5'],
            'csharp': ['.cs', '.csx'],
            'ruby': ['.rb', '.rbw'],
            'cpp': ['.cpp', '.hpp', '.cc', '.cxx', '.c++', '.c', '.h']
        }

    def _validar_extensoes_arquivos(self, arquivos: List[str], config: Dict[str, Any]) -> List[str]:
        """
        Valida e filtra arquivos baseado nas extens√µes permitidas pela linguagem configurada.

        Args:
            arquivos (List[str]): Lista de caminhos de arquivos para validar
            config (Dict[str, Any]): Configura√ß√£o da an√°lise (deve conter 'linguagem')

        Returns:
            List[str]: Lista de arquivos com extens√µes v√°lidas para a linguagem

        Note:
            Arquivos com extens√µes inv√°lidas s√£o logged como warning e removidos da lista
        """
        linguagem = config.get('linguagem', 'c').lower()
        extensoes_permitidas = self._get_extensoes_por_linguagem().get(linguagem, self._get_extensoes_por_linguagem()['c'])

        arquivos_validos = []
        arquivos_invalidos = []

        for arquivo in arquivos:
            _, ext = os.path.splitext(arquivo.lower())
            if ext in extensoes_permitidas:
                arquivos_validos.append(arquivo)
            else:
                arquivos_invalidos.append(arquivo)

        if arquivos_invalidos:
            logger.warning(f"üö´ {len(arquivos_invalidos)} arquivo(s) ignorado(s) por extens√£o incompat√≠vel com linguagem '{linguagem}':")
            for arquivo in arquivos_invalidos:
                _, ext = os.path.splitext(arquivo)
                logger.warning(f"   - {arquivo} (extens√£o: {ext})")
            logger.info(f"‚úÖ {len(arquivos_validos)} arquivo(s) v√°lido(s) para an√°lise de linguagem '{linguagem}'")

        return arquivos_validos
    
    def _get_prompt_padrao(self) -> str:
        """Retorna o prompt padr√£o para an√°lise de c√≥digo"""
        return (
            "Voc√™ √© um engenheiro de software s√™nior especializado em an√°lise de c√≥digo-fonte e arquitetura de sistemas.\n"
            "Sua miss√£o √© realizar uma an√°lise completa do arquivo de c√≥digo fornecido e estruturar sua resposta em duas se√ß√µes distintas, conforme detalhado abaixo.\n\n"
            "--------------------------------\n"
            "### SE√á√ÉO 1: FORMATO OBRIGAT√ìRIO DO GRAFO JSON\n"
            "Para a tarefa de gera√ß√£o do grafo, voc√™ DEVE gerar o JSON seguindo ESTRITAMENTE o formato, a estrutura e a riqueza de detalhes do exemplo a seguir. Preencha todos os campos poss√≠veis com base na sua an√°lise do c√≥digo, incluindo `group`, `shape`, `color` e especialmente os `metadata`.\n\n"
            "```json\n"
            "{{\n"
            '  "nodes": [],\n'
            '  "edges": [],\n'
            '  "meta": {{}}\n'
            "}}\n"
            "```\n\n"
            "--------------------------------\n"
            "### SE√á√ÉO 2: SUAS TAREFAS\n\n"
            "Com base no c√≥digo-fonte fornecido, execute as seguintes tarefas:\n\n"
            "1.  **AN√ÅLISE T√âCNICA:**\n"
            "    - Escreva uma an√°lise clara e t√©cnica sobre o prop√≥sito e a funcionalidade do c√≥digo.\n"
            "    - Descreva as responsabilidades principais da classe/fun√ß√£o.\n"
            "    - Explique as l√≥gicas de neg√≥cio e o fluxo de execu√ß√£o de ponta a ponta.\n\n"
            "2.  **GRAFO DE FLUXO (JSON):**\n"
            "    - Gere um grafo completo em formato JSON que mapeia as intera√ß√µes e chamadas no c√≥digo.\n"
            "    - Siga rigorosamente o formato rico do exemplo na SE√á√ÉO 1.\n\n"
            "--- C√ìDIGO DO ARQUIVO: {filename} ---\n"
            "```{lang}\n{code}\n```\n\n"
            "--- AN√ÅLISE COMPLETA ---\n"
        )
    
    def _construir_prompt_analise(self, arquivo: str, codigo: str, config: Dict[str, Any]) -> str:
        """Constr√≥i o prompt para an√°lise do c√≥digo"""
        prompt_template = config.get('prompt_template', self._get_prompt_padrao())
        
        # Substitui placeholders
        prompt = prompt_template.replace('{filename}', os.path.basename(arquivo))
        prompt = prompt.replace('{lang}', config.get('linguagem', 'c'))
        prompt = prompt.replace('{code}', codigo[:config.get('limite_linhas', 1000) * 10])
        
        return prompt
    
    def _extrair_json_da_resposta(self, resposta: str) -> Dict[str, Any]:
        """
        Extrai JSON estruturado da resposta do LLM usando m√∫ltiplas estrat√©gias robustas.

        Este m√©todo implementa um sistema completo de extra√ß√£o de JSON com fallbacks
        progressivos para lidar com diferentes formatos de resposta do LLM. Usa
        m√∫ltiplas estrat√©gias de regex e fallback textual para garantir m√°xima
        taxa de sucesso na extra√ß√£o dos dados estruturados.

        Args:
            resposta (str): Resposta bruta do LLM contendo JSON estruturado

        Returns:
            Dict[str, Any]: Dicion√°rio com os dados extra√≠dos. Em caso de falha
                          completa, retorna estrutura vazia com campos obrigat√≥rios.

        Note:
            Estrat√©gias de extra√ß√£o em ordem de prioridade:
            1. Bloco de c√≥digo JSON (```json ... ```)
            2. JSON entre chaves com formata√ß√£o variada
            3. An√°lise textual como fallback (extrai nodes/edges manualmente)
            4. Estrutura vazia como √∫ltimo recurso

        Raises:
            None: M√©todo sempre retorna um dicion√°rio v√°lido, tratando erros internamente

        Example:
            >>> json_data = model._extrair_json_da_resposta(resposta_llm)
            >>> nodes = json_data.get('nodes', [])
            >>> edges = json_data.get('edges', [])
        """
        try:
            logger.info(f"üîç Iniciando extra√ß√£o de JSON (resposta: {len(resposta)} caracteres)")

            import re

            # üî• MELHORIA: Estrat√©gias mais espec√≠ficas para encontrar o JSON correto
            json_patterns = [
                # Padr√µes mais espec√≠ficos primeiro - procuram por JSON com nodes/edges
                r'```json\s*(\{[^`]*"nodes"[^`]*"edges"[^`]*\})\s*```',
                r'```JSON\s*(\{[^`]*"nodes"[^`]*"edges"[^`]*\})\s*```',
                # Padr√µes para JSON que contenham nodes ou edges individualmente
                r'```json\s*(\{[^`]*"nodes"[^`]*\})\s*```',
                r'```JSON\s*(\{[^`]*"nodes"[^`]*\})\s*```',
                r'```json\s*(\{[^`]*"edges"[^`]*\})\s*```',
                r'```JSON\s*(\{[^`]*"edges"[^`]*\})\s*```',
                # Depois patterns mais gen√©ricos dentro de blocos de c√≥digo
                r'```json\s*(.*?)\s*```',
                r'```JSON\s*(.*?)\s*```',
                # Blocos de c√≥digo gen√©ricos (menos priorit√°rios)
                r'```\s*(\{[^`]*\})\s*```',
                # üî• CORRE√á√ÉO: Padr√£o mais espec√≠fico fora de blocos de c√≥digo
                # Evita capturar estruturas pequenas ou fragmentos
                r'(\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\{[^{}]*"nodes"[^{}]*\}[^{}]*\})',
                r'(\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\{[^{}]*"edges"[^{}]*\}[^{}]*\})',
            ]

            json_candidates = []
            invalid_structures = []

            for i, pattern in enumerate(json_patterns):
                matches = re.findall(pattern, resposta, re.DOTALL)
                for match in matches:
                    if isinstance(match, tuple):
                        match = match[0] if match else ""
                    json_str = match.strip()

                    # üî• Limpeza mais robusta do JSON
                    json_str = self._limpar_json_str(json_str)

                    if json_str and json_str.startswith('{') and json_str.endswith('}'):
                        # üî• MELHORIA: Filtra candidatos muito pequenos provavelmente inv√°lidos
                        if len(json_str) >= 50:  # Pelo menos 50 caracteres
                            json_candidates.append((json_str, f"pattern_{i+1}"))
                        else:
                            logger.debug(f"üîç Candidato muito pequeno descartado ({len(json_str)} chars): {json_str[:50]}...")
                            continue

            logger.info(f"üîç Encontrados {len(json_candidates)} candidatos a JSON")

            # üî• MELHORIA: Ordena candidatos por prefer√™ncia (nodes/edges primeiro)
            def candidate_priority(json_str):
                try:
                    # Verifica se tem nodes e edges
                    has_nodes = '"nodes"' in json_str
                    has_edges = '"edges"' in json_str
                    has_name = '"name"' in json_str  # Provavelmente o JSON correto

                    # üî• MELHORIA: Verifica se JSON √© muito pequeno (provavelmente inv√°lido)
                    json_length = len(json_str)
                    is_too_small = json_length < 100  # Menos de 100 caracteres provavelmente √© inv√°lido
                    has_required_keys = has_nodes or has_edges

                    # Prioridade 1 (melhor): tem nodes, edges e name, e n√£o √© muito pequeno
                    if has_nodes and has_edges and has_name and not is_too_small:
                        return 1
                    # Prioridade 2: tem nodes e edges, e n√£o √© muito pequeno
                    elif has_nodes and has_edges and not is_too_small:
                        return 2
                    # Prioridade 3: tem nodes ou edges, mas n√£o √© muito pequeno
                    elif has_required_keys and not is_too_small:
                        return 3
                    # Prioridade 4: muito pequeno (provavelmente fragmento inv√°lido)
                    elif is_too_small:
                        return 5
                    # Prioridade 5: outros (sem nodes/edges)
                    else:
                        return 4
                except:
                    return 6

            # Ordena candidatos por prioridade
            json_candidates.sort(key=lambda x: candidate_priority(x[0]))

            # Tenta cada candidato apenas uma vez
            for i, (json_str, source) in enumerate(json_candidates):
                try:
                    parsed_json = json.loads(json_str)
                    # üî• Valida√ß√£o b√°sica da estrutura
                    if self._validar_estrutura_json(parsed_json):
                        nodes_count = len(parsed_json.get('nodes', []))
                        edges_count = len(parsed_json.get('edges', []))
                        logger.info(f"‚úÖ JSON extra√≠do com sucesso (via {source}, candidato {i+1})")
                        logger.info(f"   üìä Estat√≠sticas: {nodes_count} nodes, {edges_count} edges")
                        return parsed_json
                    else:
                        # Coleta informa√ß√µes sobre estrutura inv√°lida para debugging
                        keys = list(parsed_json.keys()) if isinstance(parsed_json, dict) else "not_dict"
                        error_msg = self._last_validation_error or "erro desconhecido"
                        invalid_structures.append((source, keys, error_msg))
                except json.JSONDecodeError as e:
                    logger.debug(f"‚ùå Parse falhou no candidato {i+1}: {e}")
                    continue

            # Se houver estruturas inv√°lidas, mostra um resumo √∫til
            if invalid_structures:
                logger.warning(f"‚ö†Ô∏è {len(invalid_structures)} JSON(s) com estrutura inv√°lida:")
                # Agrupa por padr√£o para mostrar os mais problem√°ticos
                pattern_counts = {}
                for source, _, _ in invalid_structures:
                    pattern_counts[source] = pattern_counts.get(source, 0) + 1

                # Mostra os padr√µes mais problem√°ticos primeiro
                for pattern, count in sorted(pattern_counts.items(), key=lambda x: x[1], reverse=True):
                    logger.warning(f"   - {pattern}: {count} ocorr√™ncias")

                # Mostra exemplos espec√≠ficos (limitado a 2)
                for source, keys, error_msg in invalid_structures[:2]:
                    logger.warning(f"   - {source}: {error_msg}")
                    logger.warning(f"     chaves encontradas = {keys}")
                if len(invalid_structures) > 2:
                    logger.warning(f"   ... e mais {len(invalid_structures) - 2} omissos")

            # üî• Estrat√©gia 2: Extra√ß√£o manual mais sofisticada
            json_str = self._extrair_json_manual(resposta)
            if json_str:
                try:
                    parsed_json = json.loads(json_str)
                    if self._validar_estrutura_json(parsed_json):
                        nodes_count = len(parsed_json.get('nodes', []))
                        edges_count = len(parsed_json.get('edges', []))
                        logger.info(f"‚úÖ JSON extra√≠do manualmente com sucesso")
                        logger.info(f"   üìä Estat√≠sticas: {nodes_count} nodes, {edges_count} edges")
                        return parsed_json
                except json.JSONDecodeError as e:
                    logger.debug(f"‚ùå Parse manual falhou: {e}")

            # üî• Estrat√©gia 3: Tenta extrair informa√ß√µes do texto se JSON falhar completamente
            fallback_result = self._extrair_info_textual(resposta)
            if fallback_result:
                logger.warning("‚ö†Ô∏è JSON falhou, mas informa√ß√µes extra√≠das do texto")
                return fallback_result

            # Fallback para estrutura m√≠nima com informa√ß√µes de debug
            logger.warning("‚ö†Ô∏è N√£o foi poss√≠vel extrair JSON v√°lido, usando estrutura m√≠nima")
            return {
                "nodes": [],
                "edges": [],
                "meta": {
                    "parse_status": "failed",
                    "response_length": len(resposta),
                    "response_preview": resposta[:500] + "..." if len(resposta) > 500 else resposta
                }
            }

        except Exception as e:
            logger.error(f"üí• Erro cr√≠tico ao extrair JSON: {e}")
            return {
                "nodes": [],
                "edges": [],
                "meta": {"error": str(e), "parse_status": "critical_error"}
            }

    def _limpar_json_str(self, json_str: str) -> str:
        """Limpa e normaliza string JSON"""
        if not json_str:
            return ""

        # Remove caracteres problem√°ticos do in√≠cio e fim
        json_str = json_str.strip()

        # Remove marcadores de c√≥digo que possam ter sobrado
        json_str = re.sub(r'^[^\{]*', '', json_str)  # Remove tudo antes de {
        json_str = re.sub(r'[^\}]*$', '', json_str)  # Remove tudo depois de }

        # Corrige problemas comuns de formata√ß√£o
        json_str = json_str.replace('\n', ' ').replace('\r', ' ')
        json_str = re.sub(r'\s+', ' ', json_str)  # Normaliza espa√ßos

        # Remove coment√°rios inline problem√°ticos
        json_str = re.sub(r'//.*?(?=[\}\],])', '', json_str)

        # Corrige aspas simples para aspas duplas (problema comum)
        json_str = re.sub(r"'([^']*)'", r'"\1"', json_str)

        # Remove espa√ßos antes de v√≠rgulas e depois de v√≠rgulas
        json_str = re.sub(r'\s*,', ',', json_str)
        json_str = re.sub(r',\s*', ',', json_str)

        return json_str

    def _validar_estrutura_json(self, json_data: Dict[str, Any]) -> bool:
        """
        Valida se o JSON tem a estrutura esperada para an√°lise de c√≥digo.

        Args:
            json_data (Dict[str, Any]): Dados JSON a validar

        Returns:
            bool: True se estrutura √© v√°lida, False caso contr√°rio
        """
        if not isinstance(json_data, dict):
            return False

        # Verifica se tem as chaves principais
        required_keys = ['nodes', 'edges']
        missing_keys = [key for key in required_keys if key not in json_data]

        if missing_keys:
            # Debug: mostra quais chaves faltam em vez de apenas falhar
            self._last_validation_error = f"Chaves faltando: {missing_keys}"
            return False

        # Verifica se nodes e edges s√£o listas
        if not isinstance(json_data['nodes'], list):
            self._last_validation_error = f"'nodes' n√£o √© lista: {type(json_data['nodes']).__name__}"
            return False

        if not isinstance(json_data['edges'], list):
            self._last_validation_error = f"'edges' n√£o √© lista: {type(json_data['edges']).__name__}"
            return False

        # üî• MELHORIA: Valida√ß√£o mais flex√≠vel dos formatos de arestas
        # Aceita tanto "source"/"target" quanto "from"/"to"
        if json_data['edges']:
            valid_edge = False
            for edge in json_data['edges'][:3]:  # Verifica s√≥ as 3 primeiras arestas
                if isinstance(edge, dict):
                    # Formato 1: source/target
                    if 'source' in edge and 'target' in edge:
                        valid_edge = True
                        break
                    # Formato 2: from/to
                    elif 'from' in edge and 'to' in edge:
                        valid_edge = True
                        break

            if not valid_edge:
                self._last_validation_error = "Edges n√£o t√™m formato v√°lido (source/target ou from/to)"
                return False

        self._last_validation_error = None
        return True

    def _extrair_json_manual(self, resposta: str) -> str:
        """Extrai JSON manualmente com heur√≠sticas melhoradas"""
        # Procura pelo primeiro { e pelo √∫ltimo }
        start_idx = resposta.find('{')
        end_idx = resposta.rfind('}')

        if start_idx != -1 and end_idx != -1 and end_idx > start_idx:
            json_str = resposta[start_idx:end_idx + 1]

            # Valida√ß√£o b√°sica antes de retornar
            if json_str.count('{') == json_str.count('}'):  # Chaves balanceadas
                return self._limpar_json_str(json_str)

        return ""

    def _extrair_info_textual(self, resposta: str) -> Optional[Dict[str, Any]]:
        """Tenta extrair informa√ß√µes do texto quando JSON falha"""
        # Procura por men√ß√µes de fun√ß√µes e estruturas no texto
        try:
            nodes = []
            edges = []

            # Padr√µes para encontrar fun√ß√µes/vari√°veis
            func_pattern = r'\b([a-zA-Z_][a-zA-Z0-9_]*)\s*\([^)]*\)'
            var_pattern = r'\b([a-zA-Z_][a-zA-Z0-9_]*)\b'

            # Encontra fun√ß√µes
            functions = re.findall(func_pattern, resposta)
            for i, func in enumerate(set(functions[:10])):  # Limita para evitar excesso
                if len(func) > 2:  # Ignora nomes muito curtos
                    nodes.append({
                        "id": func,
                        "label": func,
                        "type": "function",
                        "pos": 100 + i * 10
                    })

            # Conecta algumas fun√ß√µes sequencialmente
            for i in range(len(nodes) - 1):
                edges.append({
                    "source": nodes[i]["id"],
                    "target": nodes[i + 1]["id"],
                    "type": "sequence"
                })

            if nodes:  # S√≥ retorna se encontrou algo √∫til
                logger.info(f"üîì Extra√≠das {len(nodes)} estruturas do texto")
                return {
                    "nodes": nodes,
                    "edges": edges,
                    "meta": {
                        "parse_status": "textual_fallback",
                        "extraction_method": "regex_textual"
                    }
                }
        except Exception as e:
            logger.debug(f"Falha na extra√ß√£o textual: {e}")

        return None

    def update_config(self, new_config: Dict[str, Any]):
        """Atualiza a configura√ß√£o da an√°lise"""
        self.config.update(new_config)

        # Atualiza a URL do OllamaService se foi alterada
        if 'llm_url' in new_config:
            new_url = self.config.get('llm_url', 'http://localhost:11434')
            self.ollama_service = OllamaService(base_url=new_url)
            logger.info(f"URL do Ollama atualizada para: {new_url}")

        logger.info(f"Configura√ß√£o atualizada: {new_config}")

    def get_config(self) -> Dict[str, Any]:
        """Retorna a configura√ß√£o atual"""
        return self.config.copy()

    def garantir_pastas(self):
        """Garante que as pastas necess√°rias existam."""
        os.makedirs("storage/data", exist_ok=True)
        os.makedirs("storage/temp", exist_ok=True)
        os.makedirs("explicabilidade", exist_ok=True)
        os.makedirs("inspecao", exist_ok=True)

    def analisar_codigo(self, arquivos: List[str], config: Dict[str, Any],
                    progress_callback: Callable = None,
                    completion_callback: Callable = None) -> str:
        """
        Inicia a an√°lise de m√∫ltiplos arquivos de c√≥digo-fonte.

        Este m√©todo inicia uma an√°lise ass√≠ncrona dos arquivos fornecidos,
        utilizando LLM para extrair informa√ß√µes estruturadas sobre o c√≥digo.
        A an√°lise √© executada em uma thread separada para n√£o bloquear a UI.

        Args:
            arquivos (List[str]): Lista de caminhos dos arquivos para analisar
            config (Dict[str, Any]): Configura√ß√µes da an√°lise
            progress_callback (Callable, optional): Callback chamado com progresso
                Recebe: (progresso_percentual, arquivo_atual, resultado_parcial)
            completion_callback (Callable, optional): Callback chamado ao finalizar
                Recebe: (resultados, erro) - erro √© None se sucesso

        Returns:
            str: ID √∫nico da tarefa de an√°lise iniciada

        Raises:
            ValueError: Se nenhum arquivo v√°lido for fornecido

        Note:
            A an√°lise pode ser controlada com os m√©todos pausar_analise(),
            retomar_analise() e parar_analise().
        """
        task_id = f"analise_{int(time.time())}"

        # SISTEMA DE CHECKPOINT - Filtra apenas arquivos pendentes
        logger.info(f"üîç Verificando {len(arquivos)} arquivos para an√°lise...")
        arquivos_pendentes = self.obter_arquivos_pendentes(arquivos, config)

        if not arquivos_pendentes:
            logger.info("‚úÖ Todos os arquivos j√° foram analisados com sucesso!")
            if completion_callback:
                completion_callback([], None)  # Retorna vazio pois n√£o h√° o que analisar
            return task_id

        # VALIDA√á√ÉO DE EXTENS√ïES - Filtra arquivos por extens√£o compat√≠vel com a linguagem
        logger.info(f"üîç Validando extens√µes de arquivo para linguagem '{config.get('linguagem', 'c')}'...")
        arquivos_validos = self._validar_extensoes_arquivos(arquivos_pendentes, config)

        if not arquivos_validos:
            logger.error("‚ùå Nenhum arquivo com extens√£o v√°lida encontrado para a linguagem configurada!")
            if completion_callback:
                completion_callback([], ValueError("Nenhum arquivo compat√≠vel com a linguagem selecionada"))
            return task_id

        logger.info(f"üéØ Iniciando an√°lise de {len(arquivos_validos)} arquivos v√°lidos (de {len(arquivos)} totais)")

        # Limpa estados anteriores
        self.is_running = True
        self.is_paused = False
        self.is_stopped = False
        self.current_progress = 0
        self.current_file = ""
        self.resultados = []

        # üîç ULTRATHINK: Executa em thread separada com tracking
        def run_analysis():
            # Logar in√≠cio da thread
            import threading
            thread_id = threading.current_thread().ident
            logger.info(f"üÜî [ULTRATHINK] AN√ÅLISE THREAD INICIADA - Thread: {thread_id}")
            logger.info(f"üîç [ULTRATHINK] Arquivos a analisar: {len(arquivos_validos)}")
            logger.debug(f"üîç [ULTRATHINK] progress_callback: {progress_callback}")
            logger.debug(f"üîç [ULTRATHINK] completion_callback: {completion_callback}")
            logger.debug(f"üîç [ULTRATHINK] progress_callback ID: {id(progress_callback) if progress_callback else 'None'}")
            logger.debug(f"üîç [ULTRATHINK] completion_callback ID: {id(completion_callback) if completion_callback else 'None'}")

            try:
                resultados = self._executar_analise_sincrona(
                    arquivos_validos, config, progress_callback, task_id
                )
                logger.info(f"‚úÖ [ULTRATHINK] _executar_analise_sincrona conclu√≠da - Thread: {thread_id}")
                
                # ‚úÖ CORRE√á√ÉO: Chamar completion callback com tratamento de erro
                if completion_callback:
                    try:
                        completion_callback(resultados, None)
                    except Exception as callback_error:
                        logger.error(f"Erro no completion callback: {callback_error}", exc_info=True)
                        
            except Exception as e:
                logger.error(f"Erro na an√°lise {task_id}: {e}")
                # ‚úÖ CORRE√á√ÉO: Chamar completion callback de erro com tratamento
                if completion_callback:
                    try:
                        completion_callback([], f"Erro: {str(e)}")
                    except Exception as callback_error:
                        logger.error(f"Erro no completion callback (erro): {callback_error}", exc_info=True)
            finally:
                self.is_running = False
        
        # Inicia a thread
        thread = threading.Thread(target=run_analysis, daemon=True)
        thread.start()
        
        logger.info(f"Tarefa {task_id} iniciada. {len(arquivos_validos)} arquivos v√°lidos para an√°lise (de {len(arquivos)} totais).")
        return task_id

    def _executar_analise_sincrona(self, arquivos: List[str], config: Dict[str, Any],
                                progress_callback: Callable, task_id: str) -> List[Dict[str, Any]]:
        """
        Executa an√°lise de forma s√≠ncrona - VERS√ÉO MAIS ROBUSTA
        """
        resultados = []
        total_arquivos = len(arquivos)
        
        logger.info(f"üéØ Iniciando an√°lise s√≠ncrona da tarefa {task_id}")
        
        for i, arquivo in enumerate(arquivos):
            # Verifica se foi parada
            if self.is_stopped:
                logger.info(f"‚èπÔ∏è Tarefa {task_id} parada pelo usu√°rio")
                break
            
            # Verifica se est√° pausada (incluindo pausa autom√°tica por API)
            while self.is_paused and not self.is_stopped:
                if self.api_pause_active:
                    # Se est√° em pausa autom√°tica, espera mais tempo e verifica status
                    time.sleep(5)  # Espera longer para pausas autom√°ticas

                    # Mostra status da pausa a cada minuto
                    if int(time.time()) % 60 == 0:
                        status_pausa = self.obter_status_pausa_api()
                        logger.info(f"‚è≥ Pausa autom√°tica: {status_pausa['motivo']}. "
                                  f"Pr√≥xima tentativa em {status_pausa['proxima_tentativa_segundos']//60} min...")
                else:
                    time.sleep(0.5)  # Pausa manual normal

            if self.is_stopped:
                break
            
            # Atualiza progresso
            self.current_file = arquivo
            self.current_progress = (i + 1) / total_arquivos * 100
            
            try:
                # Analisa arquivo individual
                resultado = self._analisar_arquivo_individual(arquivo, config)

                # Se resultado √© None, indica pausa autom√°tica por API
                if resultado is None:
                    logger.info(f"‚è∏Ô∏è An√°lise de {os.path.basename(arquivo)} pausada por limite de API. Aguardando retomada autom√°tica...")
                    # Volta para o in√≠cio do loop (onde vai esperar a pausa acabar)
                    i -= 1  # Volta para refazer este arquivo quando a an√°lise retomar
                    continue

                resultados.append(resultado)

                # üîç ULTRATHINK: Notifica progresso com debug detalhado
                if progress_callback:
                    try:
                        # üîç Logar ANTES de chamar o callback
                        import threading
                        thread_id = threading.current_thread().ident
                        logger.info(f"üÜî [ULTRATHINK] MODEL CHAMANDO CALLBACK - Thread: {thread_id}")
                        logger.info(f"üîç [ULTRATHINK] Arquivo: {arquivo}")
                        logger.info(f"üîç [ULTRATHINK] Progresso: {self.current_progress}%")
                        logger.debug(f"üîç [ULTRATHINK] Callback function: {progress_callback}")
                        logger.debug(f"üîç [ULTRATHINK] Callback ID: {id(progress_callback)}")

                        # Logar o resultado que ser√° passado
                        logger.debug(f"üîç [ULTRATHINK] Resultado status: {resultado.get('status') if resultado else 'None'}")
                        logger.debug(f"üîç [ULTRATHINK] Resultado keys: {list(resultado.keys()) if resultado else 'None'}")
                        if resultado and 'estatisticas' in resultado:
                            stats = resultado.get('estatisticas', {})
                            logger.debug(f"üîç [ULTRATHINK] Estat√≠sticas: {stats}")

                        logger.info(f"üìû [ULTRATHINK] EXECUTANDO progress_callback...")
                        progress_callback(self.current_progress, arquivo, resultado)
                        logger.info(f"‚úÖ [ULTRATHINK] progress_callback executado com sucesso")
                    except Exception as callback_error:
                        logger.error(f"‚ùå [ULTRATHINK] ERRO NO CALLBACK: {callback_error}", exc_info=True)
                        logger.error(f"üîç [ULTRATHINK] Callback function: {progress_callback}")
                        logger.error(f"üîç [ULTRATHINK] Thread ID: {thread_id}")
                        # N√£o interrompe a an√°lise por erro no callback
                else:
                    logger.warning(f"‚ö†Ô∏è [ULTRATHINK] progress_callback √© None - n√£o chamado para {arquivo}")

                logger.info(f"‚úÖ Arquivo {i+1}/{total_arquivos} analisado: {os.path.basename(arquivo)}")

            except Exception as e:
                logger.error(f"‚ùå Erro ao analisar {arquivo}: {e}")
                resultado_erro = {
                    'arquivo': arquivo,
                    'erro': str(e),
                    'timestamp': time.time(),
                    'status': 'erro'
                }
                resultados.append(resultado_erro)
                
                # ‚úÖ CORRE√á√ÉO: Notifica progresso do erro com tratamento
                if progress_callback:
                    try:
                        progress_callback(self.current_progress, arquivo, resultado_erro)
                    except Exception as callback_error:
                        logger.error(f"Erro no callback de progresso (erro): {callback_error}")
        
        # An√°lise completada
        if not self.is_stopped:
            logger.info(f"üéâ Tarefa {task_id} completada. {len(resultados)} arquivos processados.")
        else:
            logger.info(f"‚èπÔ∏è Tarefa {task_id} interrompida. {len(resultados)} arquivos processados.")

        # ‚úÖ SALVAR: Armazena resultados no modelo para acesso posterior
        self.resultados = resultados
        logger.debug(f"Resultados armazenados em self.resultados: {len(self.resultados)} itens")

        return resultados

    def _verificar_checkpoint(self, arquivo: str, config: Dict[str, Any]) -> Optional[str]:
        """
        Verifica se o arquivo j√° foi analisado com sucesso usando o sistema de checkpoint inteligente.

        Este m√©todo implementa o sistema de checkpoint que evita an√°lises redundantes,
        validando n√£o apenas a exist√™ncia do arquivo de an√°lise anterior, mas tamb√©m
        a compatibilidade da configura√ß√£o utilizada. Isso garante que an√°lises anteriores
        sejam reaproveitadas apenas quando appropriate.

        Args:
            arquivo (str): Caminho completo do arquivo fonte a ser verificado
            config (Dict[str, Any]): Configura√ß√£o atual da an√°lise para compara√ß√£o

        Returns:
            Optional[str]: Caminho do arquivo JSON de an√°lise existente se v√°lido,
                         None se n√£o existe ou √© incompat√≠vel

        Note:
            Crit√©rios de valida√ß√£o do checkpoint:
            - Arquivo JSON deve existir no diret√≥rio storage/data/
            - Status da an√°lise anterior deve ser 'sucesso'
            - Configura√ß√µes cr√≠ticas devem ser compat√≠veis:
              * llm_modelo: Modelo LLM utilizado
              * nivel_analise: N√≠vel da an√°lise
              * analisar_dependencias: Flag de depend√™ncias
              * incluir_comentarios: Flag de coment√°rios

        Example:
            >>> checkpoint = model._verificar_checkpoint('src/main.c', config)
            >>> if checkpoint:
            ...     print(f"Checkpoint v√°lido encontrado: {checkpoint}")
            ...     # Reaproveitar an√°lise anterior

        Raises:
            None: M√©todo trata exce√ß√µes internamente e retorna None em caso de erro
        """
        try:
            nome_base = os.path.basename(arquivo)

            # Determina o caminho do arquivo de an√°lise
            if "inspecao" in arquivo:
                rel_path = os.path.relpath(arquivo, "inspecao")
                analysis_path = os.path.join("storage/data", rel_path + "_analise.json")
            else:
                analysis_path = os.path.join("storage/data", f"{nome_base}_analise.json")

            # Verifica se o arquivo existe
            if not os.path.exists(analysis_path):
                return None

            # Carrega e valida o arquivo de an√°lise
            with open(analysis_path, 'r', encoding='utf-8') as f:
                analysis_data = json.load(f)

            # Verifica se o status √© sucesso e a configura√ß√£o √© compat√≠vel
            if (analysis_data.get('status') == 'sucesso' and
                'config' in analysis_data):

                stored_config = analysis_data['config']
                current_config = config

                # Verifica par√¢metros cr√≠ticos da configura√ß√£o
                config_compativel = (
                    stored_config.get('llm_modelo') == current_config.get('llm_modelo') and
                    stored_config.get('nivel_analise') == current_config.get('nivel_analise') and
                    stored_config.get('analisar_dependencias') == current_config.get('analisar_dependencias') and
                    stored_config.get('incluir_comentarios') == current_config.get('incluir_comentarios')
                )

                if config_compativel:
                    logger.info(f"‚úÖ Checkpoint encontrado para {arquivo} - an√°lise anterior reaproveitada")
                    return analysis_path
                else:
                    logger.info(f"‚ö†Ô∏è Configura√ß√£o mudou para {arquivo} - nova an√°lise necess√°ria")
                    return None
            else:
                logger.info(f"‚ùå An√°lise anterior falhou para {arquivo} - refazendo an√°lise")
                return None

        except Exception as e:
            logger.warning(f"Erro ao verificar checkpoint para {arquivo}: {e}")
            return None

    def _analisar_arquivo_individual(self, arquivo: str, config: Dict[str, Any]) -> Dict[str, Any]:
        """
        Analisa um arquivo individual usando LLM - VERS√ÉO CORRIGIDA COM CHECKPOINT
        """
        logger.info(f"üìÅ Analisando arquivo: {arquivo}")

        # VERIFICA√á√ÉO DE CHECKPOINT - Evita an√°lise redundante
        checkpoint_path = self._verificar_checkpoint(arquivo, config)
        if checkpoint_path:
            try:
                with open(checkpoint_path, 'r', encoding='utf-8') as f:
                    stored_result = json.load(f)

                # Retorna resultado armazenado com marca√ß√£o de checkpoint
                return {
                    'arquivo': arquivo,
                    'nome_arquivo': os.path.basename(arquivo),
                    'analise_texto': stored_result.get('analise_texto', ''),
                    'analise_json': stored_result.get('analise_json', {}),
                    'timestamp': stored_result.get('timestamp', time.time()),
                    'tempo_processamento': 0,  # Tempo zero pois foi do checkpoint
                    'checkpoint': True,  # Marca√ß√£o de que veio do checkpoint
                    'checkpoint_path': checkpoint_path
                }
            except Exception as e:
                logger.warning(f"Erro ao carregar checkpoint para {arquivo}: {e}")

        try:
            # L√™ o conte√∫do do arquivo
            with open(arquivo, 'r', encoding='utf-8', errors='ignore') as f:
                codigo = f.read()
            
            # Verifica se o arquivo est√° vazio
            if not codigo.strip():
                logger.warning(f"üì≠ Arquivo vazio: {arquivo}")
                return {
                    'arquivo': arquivo,
                    'nome_arquivo': os.path.basename(arquivo),
                    'analise_texto': "Arquivo vazio",
                    'analise_json': {"nodes": [], "edges": [], "meta": {"empty_file": True}},
                    'timestamp': time.time(),
                    'config': config,
                    'status': 'vazio'
                }
            
            # Prepara o prompt para an√°lise
            prompt = self._construir_prompt_analise(arquivo, codigo, config)
            
            # Obt√©m a an√°lise do LLM
            modelo = config.get('llm_modelo', 'llama2')
            tamanho_contexto = config.get('llm_tamanho_contexto', 4096)
            temperatura = config.get('llm_temperatura', 0.7)
            
            logger.info(f"ü§ñ Solicitando an√°lise do LLM (modelo: {modelo}, contexto: {tamanho_contexto})")

            analise, tempo_llm = self.ollama_service.generate_response(
                model=modelo,
                prompt=prompt,
                context_size=tamanho_contexto,
                temperature=temperatura
            )

            # ‚úÖ CORRE√á√ÉO: Melhor tratamento de erro para respostas do Ollama
            if not analise:
                # üî• MELHORIA: Captura a √∫ltima mensagem de erro do OllamaService
                last_error = getattr(self.ollama_service, '_last_error', None)
                if last_error and ('429' in last_error or 'rate limit' in last_error.lower() or 'too many requests' in last_error.lower()):
                    # Erro de rate limit detectado - ativa pausa autom√°tica
                    error_msg = f"Erro de limite de API detectado: {last_error}"
                    logger.error(f"üö´ {error_msg}")
                    self._ativar_pausa_api(f"Limite de API atingido (rate_limit)")
                    return None  # An√°lise pausada
                else:
                    error_msg = f"Falha ao obter an√°lise do LLM - modelo '{modelo}' pode n√£o estar dispon√≠vel"
                    logger.error(f"‚ùå {error_msg}")
                    raise Exception(error_msg)

            logger.info(f"üì® Resposta do LLM recebida: {len(analise)} caracteres")
            if tempo_llm:
                logger.info(f"‚è±Ô∏è Tempo de processamento LLM: {tempo_llm:.2f} segundos")
            
            # Processa a resposta para extrair JSON
            resultado_json = self._extrair_json_da_resposta(analise)
            
            # Log das estat√≠sticas finais
            nodes_count = len(resultado_json.get('nodes', []))
            edges_count = len(resultado_json.get('edges', []))
            logger.info(f"üìä An√°lise conclu√≠da: {nodes_count} nodes, {edges_count} edges extra√≠dos")
            
            # Estrutura do resultado
            resultado = {
                'arquivo': arquivo,
                'nome_arquivo': os.path.basename(arquivo),
                'analise_texto': analise,
                'analise_json': resultado_json,
                'timestamp': time.time(),
                'config': config,
                'status': 'sucesso',
                'tempo_llm': tempo_llm,  # Tempo de processamento da LLM em segundos
                'estatisticas': {
                    'nodes_count': nodes_count,
                    'edges_count': edges_count,
                    'texto_length': len(analise),
                    'tempo_processamento': tempo_llm
                }
            }
            
            # Salva resultado em JSON
            output_path = self._salvar_resultado_json(resultado, arquivo)
            resultado['output_path'] = output_path
            
            logger.info(f"üíæ Resultado salvo em: {output_path}")
            return resultado
            
        except Exception as e:
            error_str = str(e)
            logger.error(f"üí• Erro ao analisar {arquivo}: {error_str}")

            # Usa o OllamaService para identificar o tipo de erro
            error_type = self.ollama_service.identificar_tipo_erro(error_str)

            # Verifica√ß√£o espec√≠fica para erros de API que requerem pausa autom√°tica
            if error_type in ['rate_limit', 'quota_exceeded']:
                logger.error(f"üö´ Erro de limite de API detectado: {error_str}")
                self._ativar_pausa_api(f"Limite de API atingido ({error_type})")
            elif error_type == 'vram':
                logger.warning(f"üî¥ Erro de mem√≥ria VRAM detectado para {arquivo}")
            elif error_type == 'api_error':
                logger.warning(f"üî¥ Erro de API detectado para {arquivo}")
            elif error_type == 'model_unavailable':
                logger.warning(f"üî¥ Modelo n√£o dispon√≠vel para {arquivo}")
            elif error_type == 'timeout':
                logger.warning(f"üî¥ Timeout detectado para {arquivo}")

            # Salva informa√ß√£o do erro para retomada posterior
            resultado_erro = {
                'arquivo': arquivo,
                'erro': error_str,
                'timestamp': time.time(),
                'status': 'erro',
                'error_type': error_type,
                'config': config  # Salva config para verificar compatibilidade futura
            }

            # üî• CORRE√á√ÉO CR√çTICA: N√ÉO SALVA ARQUIVOS COM ERROS QUE N√ÉO SEJAM DE PAUSA
            # Evita que arquivos com erro sejam considerados "analisados" futuramente

            # Se for erro de API que requer pausa, n√£o retorna resultado ainda
            # A an√°lise ser√° retomada automaticamente quando a API voltar
            if error_type in ['rate_limit', 'quota_exceeded']:
                logger.info(f"üö¶ An√°lise pausada: {error_str}. Retentativa em 30 minutos...")
                return None  # Indica que a an√°lise est√° pausada
            else:
                # üî• IMPORTANTE: Para erros n√£o-relacionados a pausa (timeout, model unavailable, etc.)
                # N√ÉO salvar arquivo de resultado para permitir rean√°lise futura
                logger.warning(f"‚ö†Ô∏è Erro em {arquivo} n√£o gerar√° arquivo (permitir√° rean√°lise): {error_str}")
                return resultado_erro

    def analisar_status_analises(self, arquivos_projeto: List[str], config: Dict[str, Any]) -> Dict[str, Any]:
        """
        Analisa o status de todos os arquivos de an√°lise no projeto
        Retorna informa√ß√µes detalhadas sobre o que est√° completo, pendente ou com erro
        """
        logger.info("üìä Analisando status das an√°lises do projeto...")

        status = {
            'total_arquivos': len(arquivos_projeto),
            'concluidos': [],
            'pendentes': [],
            'erros': [],
            'incompativeis': [],
            'resumo': {
                'sucesso': 0,
                'falha': 0,
                'pendente': 0,
                'incompativel': 0
            }
        }

        for arquivo in arquivos_projeto:
            try:
                nome_base = os.path.basename(arquivo)

                # Determina o caminho do arquivo de an√°lise
                if "inspecao" in arquivo:
                    rel_path = os.path.relpath(arquivo, "inspecao")
                    analysis_path = os.path.join("storage/data", rel_path + "_analise.json")
                else:
                    analysis_path = os.path.join("storage/data", f"{nome_base}_analise.json")

                # Verifica se o arquivo de an√°lise existe
                if not os.path.exists(analysis_path):
                    status['pendentes'].append({
                        'arquivo': arquivo,
                        'motivo': 'N√£o analisado anteriormente'
                    })
                    status['resumo']['pendente'] += 1
                    continue

                # Carrega o arquivo de an√°lise
                with open(analysis_path, 'r', encoding='utf-8') as f:
                    analysis_data = json.load(f)

                analysis_status = analysis_data.get('status', 'desconhecido')

                if analysis_status == 'sucesso':
                    # Verifica compatibilidade da configura√ß√£o
                    if 'config' in analysis_data:
                        stored_config = analysis_data['config']
                        config_compativel = (
                            stored_config.get('llm_modelo') == config.get('llm_modelo') and
                            stored_config.get('nivel_analise') == config.get('nivel_analise') and
                            stored_config.get('analisar_dependencias') == config.get('analisar_dependencias') and
                            stored_config.get('incluir_comentarios') == config.get('incluir_comentarios')
                        )

                        if config_compativel:
                            status['concluidos'].append({
                                'arquivo': arquivo,
                                'analysis_path': analysis_path,
                                'timestamp': analysis_data.get('timestamp'),
                                'tempo_llm': analysis_data.get('tempo_llm', 0)
                            })
                            status['resumo']['sucesso'] += 1
                        else:
                            status['incompativeis'].append({
                                'arquivo': arquivo,
                                'motivo': 'Configura√ß√£o alterada',
                                'analysis_path': analysis_path,
                                'stored_config': stored_config
                            })
                            status['resumo']['incompativel'] += 1
                    else:
                        # An√°lise bem-sucedida mas sem config - assume compat√≠vel
                        status['concluidos'].append({
                            'arquivo': arquivo,
                            'analysis_path': analysis_path,
                            'timestamp': analysis_data.get('timestamp'),
                            'tempo_llm': analysis_data.get('tempo_llm', 0)
                        })
                        status['resumo']['sucesso'] += 1

                elif analysis_status == 'erro':
                    error_type = analysis_data.get('error_type', 'geral')
                    status['erros'].append({
                        'arquivo': arquivo,
                        'erro': analysis_data.get('erro', 'Erro desconhecido'),
                        'error_type': error_type,
                        'timestamp': analysis_data.get('timestamp'),
                        'analysis_path': analysis_path
                    })
                    status['resumo']['falha'] += 1

                    # üî• CORRE√á√ÉO: Trata falhas como pendentes para rean√°lise, exceto rate limit
                    if error_type not in ['rate_limit', 'quota_exceeded']:
                        status['pendentes'].append({
                            'arquivo': arquivo,
                            'motivo': f'An√°lise anterior falhou: {error_type}',
                            'retry': True  # Indica que pode ser reanalisado
                        })
                        status['resumo']['pendente'] += 1
                        status['resumo']['falha'] -= 1  # Remove da contagem de falha (agora √© pendente)

                else:
                    # Status desconhecido - trata como pendente
                    status['pendentes'].append({
                        'arquivo': arquivo,
                        'motivo': f'Status desconhecido: {analysis_status}'
                    })
                    status['resumo']['pendente'] += 1

            except Exception as e:
                logger.warning(f"Erro ao analisar status de {arquivo}: {e}")
                status['pendentes'].append({
                    'arquivo': arquivo,
                    'motivo': f'Erro ao ler an√°lise: {str(e)}'
                })
                status['resumo']['pendente'] += 1

        # Log do resumo
        logger.info(f"üìà Status da an√°lise: {status['resumo']['sucesso']} conclu√≠dos, "
                   f"{status['resumo']['pendente']} pendentes, "
                   f"{status['resumo']['falha']} com erro, "
                   f"{status['resumo']['incompativel']} incompat√≠veis")

        return status

    def obter_arquivos_pendentes(self, arquivos_projetos: List[str], config: Dict[str, Any]) -> List[str]:
        """
        Retorna lista de arquivos que precisam ser analisados
        """
        status = self.analisar_status_analises(arquivos_projetos, config)

        # Arquivos pendentes incluem: nunca analisados + com erro + incompat√≠veis
        arquivos_pendentes = []

        # Adiciona nunca analisados
        for item in status['pendentes']:
            arquivos_pendentes.append(item['arquivo'])

        # Adiciona com erro (exceto erros de modelo indispon√≠vel)
        for item in status['erros']:
            if item['error_type'] != 'model_unavailable':
                arquivos_pendentes.append(item['arquivo'])

        # Adiciona incompat√≠veis
        for item in status['incompativeis']:
            arquivos_pendentes.append(item['arquivo'])

        logger.info(f"üéØ Identificados {len(arquivos_pendentes)} arquivos para an√°lise (de {len(arquivos_projetos)} totais)")

        return arquivos_pendentes

    def forcar_retentativa_api(self) -> Dict[str, Any]:
        """
        For√ßa uma tentativa imediata de reconex√£o com a API
        √ötil se o usu√°rio quer testar se a API voltou antes do tempo
        """
        if not self.api_pause_active:
            return {
                'status': 'nao_pausado',
                'mensagem': 'N√£o h√° pausa autom√°tica ativa no momento'
            }

        logger.info("üîÑ For√ßando tentativa imediata de reconex√£o com API...")
        if self.notifier:
            self.notifier.info("üîÑ Testando conex√£o com API...")

        if self.ollama_service.check_connection():
            logger.info("‚úÖ API respondeu! Retomando an√°lise...")
            if self.notifier:
                self.notifier.success("‚úÖ API dispon√≠vel! Retomando an√°lise...")
            self._desativar_pausa_api()
            return {
                'status': 'sucesso',
                'mensagem': 'API dispon√≠vel! An√°lise retomada.'
            }
        else:
            logger.warning("‚ùå API ainda n√£o respondeu.")
            if self.notifier:
                self.notifier.warning("‚ùå API ainda indispon√≠vel.")
            return {
                'status': 'falha',
                'mensagem': 'API ainda n√£o respondeu. Continuando aguardo autom√°tico.'
            }

    def cancelar_pausa_automatica(self) -> Dict[str, Any]:
        """
        Cancela a pausa autom√°tica e interrompe a an√°lise
        √ötil se o usu√°rio quer interromper completamente
        """
        if not self.api_pause_active:
            return {
                'status': 'nao_pausado',
                'mensagem': 'N√£o h√° pausa autom√°tica ativa no momento'
            }

        logger.info("üö´ Cancelando pausa autom√°tica por solicita√ß√£o do usu√°rio...")
        if self.notifier:
            self.notifier.warning("üö´ Pausa autom√°tica cancelada. An√°lise interrompida.")

        self._desativar_pausa_api()
        self.parar_analise()

        return {
            'status': 'sucesso',
            'mensagem': 'Pausa autom√°tica cancelada e an√°lise interrompida.'
        }

    def verificar_status_completo(self, pasta_projeto: str = "inspecao/") -> Dict[str, Any]:
        """
        M√©todo p√∫blico para verificar status completo de todas as an√°lises
        √ötil para interface mostrar resumo do progresso
        """
        try:
            # Encontra todos os arquivos de c√≥digo no projeto
            arquivos_projeto = []

            # Obt√©m a configura√ß√£o atual de linguagem
            config = self.get_config()
            linguagem = config.get('linguagem', 'c')
            extensoes_permitidas = self._get_extensoes_por_linguagem().get(linguagem, ['.c', '.h'])

            for root, dirs, files in os.walk(pasta_projeto):
                for file in files:
                    if any(file.endswith(ext) for ext in extensoes_permitidas):
                        arquivos_projeto.append(os.path.join(root, file))

            if not arquivos_projeto:
                return {
                    'status': 'erro',
                    'mensagem': f'Nenhum arquivo de c√≥digo encontrado em {pasta_projeto}',
                    'arquivos_total': 0
                }

            # Usa a configura√ß√£o atual
            status = self.analisar_status_analises(arquivos_projeto, config)

            # Adiciona informa√ß√µes extras para a interface
            status.update({
                'status': 'sucesso',
                'pasta_projeto': pasta_projeto,
                'config_atual': {
                    'modelo': config.get('llm_modelo'),
                    'url': config.get('llm_url'),
                    'nivel_analise': config.get('nivel_analise')
                }
            })

            # Calcula economia de tempo/requisi√ß√µes
            total_tempo_economizado = sum(
                item.get('tempo_llm', 0) for item in status['concluidos']
            )
            status['economia'] = {
                'arquivos_ignorados': len(status['concluidos']),
                'tempo_economizado_segundos': total_tempo_economizado,
                'requisicoes_economizadas': len(status['concluidos'])
            }

            # Adiciona status da pausa autom√°tica por API
            status['pausa_automatica'] = self.obter_status_pausa_api()

            # Adiciona informa√ß√µes sobre a an√°lise atual
            status['analise_atual'] = {
                'em_andamento': self.is_running,
                'arquivo_atual': self.current_file,
                'progresso_percentual': self.current_progress,
                'pausada': self.is_paused
            }

            return status

        except Exception as e:
            logger.error(f"Erro ao verificar status completo: {e}")
            return {
                'status': 'erro',
                'mensagem': f'Erro ao verificar status: {str(e)}',
                'arquivos_total': 0
            }

    def limpar_analises_com_erro(self, pasta_projeto: str = "inspecao/", tipos_erro: List[str] = None) -> Dict[str, Any]:
        """
        Remove arquivos de an√°lise com erros espec√≠ficos para permitir rean√°lise
        """
        if tipos_erro is None:
            tipos_erro = ['vram', 'timeout', 'api_error']  # Erros que podem ser tempor√°rios

        try:
            config = self.get_config()
            linguagem = config.get('linguagem', 'c')
            extensoes_permitidas = self._get_extensoes_por_linguagem().get(linguagem, ['.c', '.h'])

            arquivos_projeto = []
            for root, dirs, files in os.walk(pasta_projeto):
                for file in files:
                    if any(file.endswith(ext) for ext in extensoes_permitidas):
                        arquivos_projeto.append(os.path.join(root, file))

            status = self.analisar_status_analises(arquivos_projeto, config)
            removidos = 0

            for item in status['erros']:
                if item['error_type'] in tipos_erro:
                    try:
                        os.remove(item['analysis_path'])
                        logger.info(f"üóëÔ∏è Removida an√°lise com erro ({item['error_type']}): {item['arquivo']}")
                        removidos += 1
                    except Exception as e:
                        logger.warning(f"Erro ao remover arquivo {item['analysis_path']}: {e}")

            logger.info(f"‚úÖ Limpeza conclu√≠da: {removidos} arquivos de an√°lise removidos")
            return {
                'status': 'sucesso',
                'arquivos_removidos': removidos,
                'tipos_erro_processados': tipos_erro
            }

        except Exception as e:
            logger.error(f"Erro na limpeza de an√°lises: {e}")
            return {
                'status': 'erro',
                'mensagem': f'Erro na limpeza: {str(e)}',
                'arquivos_removidos': 0
            }

    def _salvar_resultado_json(self, resultado: Dict[str, Any], arquivo_original: str) -> str:
        """Salva o resultado da an√°lise em JSON com valida√ß√£o robusta"""
        try:
            nome_base = os.path.basename(arquivo_original)

            # üî• MELHORIA: Valida e corrige resultado antes de salvar
            resultado_validado = self._validar_e_corrigir_resultado(resultado, arquivo_original)

            # Cria estrutura de diret√≥rios baseada no arquivo original
            if "inspecao" in arquivo_original:
                rel_path = os.path.relpath(arquivo_original, "inspecao")
                output_path = os.path.join("storage/data", rel_path + "_analise.json")
            else:
                output_path = os.path.join("storage/data", f"{nome_base}_analise.json")

            os.makedirs(os.path.dirname(output_path), exist_ok=True)

            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(resultado_validado, f, indent=2, ensure_ascii=False)

            # üî• Valida√ß√£o final do JSON salvo
            try:
                with open(output_path, 'r', encoding='utf-8') as f:
                    json.load(f)  # Valida se o JSON est√° bem formado
            except json.JSONDecodeError as e:
                logger.error(f"‚ùå JSON salvo est√° malformado: {e}")
                # Salva vers√£o de emerg√™ncia
                with open(output_path, 'w', encoding='utf-8') as f:
                    json.dump(self._criar_resultado_emergencia(arquivo_original), f, indent=2, ensure_ascii=False)

            logger.debug(f"Resultado salvo em: {output_path}")
            return output_path

        except Exception as e:
            logger.error(f"Erro ao salvar resultado JSON para {arquivo_original}: {e}")
            return ""

    def _validar_e_corrigir_resultado(self, resultado: Dict[str, Any], arquivo_original: str) -> Dict[str, Any]:
        """Valida e corrige o resultado antes de salvar"""
        # üî• Verifica se o resultado tem estrutura v√°lida
        if not isinstance(resultado, dict):
            logger.warning(f"‚ö†Ô∏è Resultado inv√°lido para {arquivo_original}, criando estrutura de emerg√™ncia")
            return self._criar_resultado_emergencia(arquivo_original)

        # üî• Verifica se tem dados de an√°lise v√°lidos
        if 'status' not in resultado:
            resultado['status'] = 'sucesso'  # Assume sucesso se n√£o especificado

        # üî• Valida e corrige dados do grafo
        analise_json = resultado.get('analise_json', {})

        if not isinstance(analise_json, dict):
            logger.warning(f"‚ö†Ô∏è analise_json inv√°lido para {arquivo_original}")
            analise_json = {}

        # üî• Verifica se nodes e edges s√£o listas v√°lidas
        nodes = analise_json.get('nodes', [])
        edges = analise_json.get('edges', [])

        if not isinstance(nodes, list):
            nodes = []
            logger.warning(f"‚ö†Ô∏è nodes n√£o √© lista para {arquivo_original}")

        if not isinstance(edges, list):
            edges = []
            logger.warning(f"‚ö†Ô∏è edges n√£o √© lista para {arquivo_original}")

        # üî• CORRE√á√ÉO: Se n√£o h√° nodes nem edges E √© um erro, N√ÉO gera grafo m√≠nimo
        # Isso evita que arquivos com erro sejam considerados "analisados"
        if not nodes and not edges:
            # Verifica se o resultado indica erro
            if resultado.get('status') == 'erro':
                logger.warning(f"‚ö†Ô∏è Erro na an√°lise de {arquivo_original} - n√£o gerando grafo m√≠nimo")
                # Cria estrutura vazia para indicar falha sem marcar como analisado
                analise_json = {
                    "nodes": [],
                    "edges": [],
                    "meta": {
                        "generated": "error_fallback",
                        "reason": "analysis_failed",
                        "error": resultado.get('erro', 'Unknown error')
                    }
                }
            else:
                # Apenas gera grafo m√≠nimo se n√£o for erro (ex: arquivo realmente sem c√≥digo)
                nome_arquivo = os.path.basename(arquivo_original)
                analise_json = {
                    "nodes": [{
                        "id": nome_arquivo,
                        "label": nome_arquivo,
                        "type": "file",
                        "pos": 100
                    }],
                    "edges": [],
                    "meta": {
                        "generated": "auto_minimal",
                        "reason": "no_valid_data_found"
                    }
                }
                logger.warning(f"üîß Gerado grafo m√≠nimo para {arquivo_original}")

        # üî• Corrige e enriquece os dados
        resultado['analise_json'] = analise_json
        resultado['timestamp'] = resultado.get('timestamp', time.time())

        # üî• Adiciona estat√≠sticas se n√£o existirem
        if 'estatisticas' not in resultado:
            resultado['estatisticas'] = {
                "nodes_count": len(nodes),
                "edges_count": len(edges),
                "tempo_processamento": resultado.get('tempo_llm', 0)
            }

        # üî• Valida√ß√£o final
        if len(nodes) == 0 and len(edges) == 0:
            logger.warning(f"‚ö†Ô∏è Resultado sem dados de grafo para {arquivo_original}")

        return resultado

    def _criar_resultado_emergencia(self, arquivo_original: str) -> Dict[str, Any]:
        """Cria um resultado de emerg√™ncia v√°lido para arquivo que falhou completamente"""
        nome_arquivo = os.path.basename(arquivo_original)

        return {
            "arquivo": arquivo_original,
            "nome_arquivo": nome_arquivo,
            "status": "sucesso",
            "analise_texto": f"An√°lise de {nome_arquivo} conclu√≠da com dados m√≠nimos",
            "analise_json": {
                "nodes": [{
                    "id": nome_arquivo,
                    "label": nome_arquivo,
                    "type": "file",
                    "pos": 100,
                    "color": "#888888"
                }],
                "edges": [],
                "meta": {
                    "generated": "emergency_fallback",
                    "reason": "complete_analysis_failure"
                }
            },
            "timestamp": time.time(),
            "config": self.config if hasattr(self, 'config') else {},
            "estatisticas": {
                "nodes_count": 1,
                "edges_count": 0,
                "tempo_processamento": 0
            },
            "error_recovery": True
        }

    def pausar_analise(self) -> bool:
        """Pausa a an√°lise atual"""
        if self.is_running and not self.is_paused:
            self.is_paused = True
            logger.info("‚è∏Ô∏è An√°lise pausada")
            if self.notifier:
                self.notifier.info("An√°lise pausada")
            return True
        return False

    def retomar_analise(self) -> bool:
        """Retoma a an√°lise pausada"""
        if self.is_paused:
            self.is_paused = False
            logger.info("‚ñ∂Ô∏è An√°lise retomada")
            if self.notifier:
                self.notifier.info("An√°lise retomada")
            return True
        return False

    def parar_analise(self) -> bool:
        """Para a an√°lise atual"""
        if self.is_running:
            self.is_stopped = True
            self.is_paused = False
            logger.info("‚èπÔ∏è An√°lise parada")
            if self.notifier:
                self.notifier.info("An√°lise parada")
            return True
        return False

    def get_status_analise(self) -> Dict[str, Any]:
        """Retorna o status atual da an√°lise"""
        return {
            'executando': self.is_running and not self.is_stopped,
            'pausada': self.is_paused,
            'parada': self.is_stopped,
            'completada': not self.is_running and not self.is_stopped,
            'progresso': self.current_progress,
            'arquivo_atual': self.current_file,
            'resultados_count': len(self.resultados),
            'resultado': self.resultados  # ‚úÖ ADICIONADO: Inclui os resultados completos
        }

    def testar_conexao_ollama(self) -> Dict[str, Any]:
        """Testa a conex√£o com o Ollama"""
        try:
            if self.config.get('llm_url'):
                self.ollama_service.base_url = self.config['llm_url']
            
            conectado = self.ollama_service.check_connection()
            modelos = self.ollama_service.get_available_models() if conectado else []
            
            return {
                'conectado': conectado,
                'modelos': modelos,
                'url': self.config.get('llm_url', 'http://localhost:11434')
            }
        except Exception as e:
            logger.error(f"Erro ao testar conex√£o Ollama: {e}")
            return {
                'conectado': False,
                'modelos': [],
                'url': self.config.get('llm_url', 'http://localhost:11434'),
                'erro': str(e)
            }

    def is_analise_ativa(self) -> bool:
        """Verifica se h√° uma an√°lise ativa"""
        return self.is_running and not self.is_stopped

    def shutdown(self):
        """Desliga o model adequadamente"""
        logger.info("Executando shutdown do AnaliseModel")
        self.parar_analise()
        logger.info("AnaliseModel shutdown completo")